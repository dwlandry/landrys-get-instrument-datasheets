{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Instrument Datasheets\n",
    "### Program written by David Landry\n",
    "The purpose of this book is to scan project folders, identify instrument datasheets, copy them to a known location if new, override existing file in known location if newer, create an index of spec sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import scandir, walk\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime\n",
    "from sys import exit\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import logging\n",
    "\n",
    "instrument_destination_parent = \"E:\\\\OneDrive\\\\My Programming Projects\\\\Get Instrument Datasheets\\\\Go-Bys - Instrument Datasheets\"\n",
    "#instrument_destination_parent = \"Go-Bys - Instrument Datasheets\"\n",
    "#instrument_destination_parent = \"N:\\\\users\\\\dwlandry\\\\OneDrive\\\\My Programming Projects\\\\Get Instrument Datasheets\\\\Go-Bys - Instrument Datasheets\"\n",
    "\n",
    "\n",
    "current_year = date.today().year\n",
    "num_of_years_to_search = 5\n",
    "start_year = current_year - num_of_years_to_search\n",
    "\n",
    "root_folders_sulphur = []\n",
    "root_folders_texas = []\n",
    "\n",
    "for i in range(start_year, current_year + 1):\n",
    "    folder_sulphur = '//reconshare02/Projects/' + str(i)\n",
    "    if os.path.isdir(folder_sulphur): root_folders_sulphur.append(folder_sulphur) \n",
    "    \n",
    "    folder_texas = '//reconqnaptx/TX-Projects/Tx Projects/' + str(i)\n",
    "    if os.path.isdir(folder_texas): root_folders_texas.append(folder_texas) \n",
    "    \n",
    "\n",
    "search_string = '(\\.doc|\\.xls)'\n",
    "\n",
    "index = ['client-folder', 'project', 'filename', 'date-modified', 'source-folder']\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_FILENAME = instrument_destination_parent + '\\\\script_log.log'\n",
    "logging.basicConfig(filename=LOG_FILENAME, filemode='w',level=logging.DEBUG)\n",
    "logging.info('--------------------------------------------------')\n",
    "logging.info('RUN DATE: ' + datetime.today().strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_list_of_lists(l):\n",
    "    #print('Flattening list of lists ...')\n",
    "    try:\n",
    "        flat_list = [item for sublist in l for item in sublist]\n",
    "        return flat_list\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def get_immediate_subdirectories(a_dir):\n",
    "    #print('Getting immediate subdirectories from', a_dir,'...')\n",
    "    return [os.path.abspath(os.path.join(a_dir, name)) for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "def get_filepaths(folder, search_string):\n",
    "    #print('Getting filepaths from', folder, 'using search string (', *search_string,') ...')\n",
    "    results = []\n",
    "    for dirpath, dirnames, files in walk(folder):\n",
    "        for name in files:\n",
    "            if re.search(search_string, name.lower()):\n",
    "                #results.append(os.path.join(dirpath, name))\n",
    "                path = os.path.join(dirpath, name)\n",
    "                results.append(path)\n",
    "    return results\n",
    "\n",
    "def get_client_folders_from_root_folders(root_folders):\n",
    "    #print('Getting client folders from root folders ...')\n",
    "    client_folders = []\n",
    "    for folder in root_folders:\n",
    "        client_folders.append(get_immediate_subdirectories(folder))\n",
    "    client_folders = flatten_list_of_lists(client_folders)\n",
    "    return client_folders\n",
    "\n",
    "def get_project_folders_from_client_folders(client_folders):\n",
    "    #print('Getting project folders from client folders ...')\n",
    "    project_folders = []\n",
    "    for folder in client_folders:\n",
    "        project_folders.append(get_immediate_subdirectories(folder))\n",
    "    project_folders = flatten_list_of_lists(project_folders)\n",
    "    return project_folders\n",
    "\n",
    "def get_instrument_files_from_project_folders(project_folders):\n",
    "    #print ('Getting instrument files from project folders ...')\n",
    "    instrument_files = []\n",
    "    \n",
    "    for project_folder in project_folders:\n",
    "        instrument_search_folders = [project_folder + '/electrical_instrumentation/instrument engineering/09 - Spec Sheets']\n",
    "        for folder in instrument_search_folders:\n",
    "            if os.path.isdir(folder):\n",
    "                instrument_files.append(get_filepaths(folder, search_string))\n",
    "    instrument_files = flatten_list_of_lists(instrument_files)\n",
    "    return instrument_files\n",
    "\n",
    "def process_instrument_files(instrument_files, int_value_for_project_part_of_path, df):\n",
    "    #print('Processing instrument files ...')\n",
    "    project_part = int_value_for_project_part_of_path\n",
    "    client_part = project_part - 1\n",
    "    year_part = client_part - 1\n",
    "    for file in instrument_files:\n",
    "        p = Path(file)\n",
    "        project = p.parts[project_part]\n",
    "        client = p.parts[client_part]\n",
    "        year = p.parts[year_part]\n",
    "        folder_name = p.parts[len(p.parts) - 2]\n",
    "        dst_folder = instrument_destination_parent +'/' + client +'/' + project\n",
    "        \n",
    "        src_path = os.path.abspath(file)\n",
    "        (src_filename, src_ext) = os.path.splitext(p.parts[len(p.parts)-1])\n",
    "        \n",
    "        try:\n",
    "            src_modified = os.stat(src_path).st_mtime\n",
    "            \n",
    "            dtetime = datetime.fromtimestamp(src_modified).strftime('%Y-%m-%d-%H%M')\n",
    "            dst_filename = src_filename + '_' + dtetime\n",
    "            dst_path = os.path.abspath(dst_folder + '/' + dst_filename + src_ext)\n",
    "            \n",
    "            if os.path.exists(dst_path):\n",
    "                # File already exists.\n",
    "                # Note that there is no need to compare src_modified time and dst_modifed time since the \n",
    "                # datetime is appended to the destinattion filename.\n",
    "                creation_datetime = datetime.fromtimestamp(os.path.getctime(dst_path)).strftime('%m-%d-%Y')\n",
    "                modified_datetime = datetime.fromtimestamp(os.path.getmtime(dst_path)).strftime('%m-%d-%Y')\n",
    "                df = df.append({'YEAR': year,\n",
    "                                'CLIENT': client,\n",
    "                                'PROJECT': project,\n",
    "                                'SOURCE FOLDER': folder_name,\n",
    "                                'SOURCE PATH': src_path,\n",
    "                                'DESTINATION FOLDER': dst_folder,\n",
    "                                'DESTINATION PATH': dst_path,\n",
    "                                'DATE ADDED': creation_datetime,\n",
    "                                'DATE MODIFIED': modified_datetime,\n",
    "                                'STATUS': 'Existing',\n",
    "                                'FILENAME': src_filename,\n",
    "                                'FILENAME WITH TIMESTAMP': dst_filename,\n",
    "                                'FILE EXTENSION': src_ext\n",
    "                               }, ignore_index=True)\n",
    "                \n",
    "            else:\n",
    "                # New File\n",
    "                os.makedirs(dst_folder, exist_ok=True)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                \n",
    "                creation_datetime = datetime.fromtimestamp(os.path.getctime(dst_path)).strftime('%m-%d-%Y')\n",
    "                modified_datetime = datetime.fromtimestamp(os.path.getmtime(dst_path)).strftime('%m-%d-%Y')\n",
    "                df = df.append({'YEAR': year,\n",
    "                                'CLIENT': client,\n",
    "                                'PROJECT': project,\n",
    "                                'SOURCE FOLDER': folder_name,\n",
    "                                'SOURCE PATH': src_path,\n",
    "                                'DESTINATION FOLDER': dst_folder,\n",
    "                                'DESTINATION PATH': dst_path,\n",
    "                                'DATE ADDED': creation_datetime,\n",
    "                                'DATE MODIFIED': modified_datetime,\n",
    "                                'STATUS': 'New',\n",
    "                                'FILENAME': src_filename,\n",
    "                                'FILENAME WITH TIMESTAMP': dst_filename,\n",
    "                                'FILE EXTENSION': src_ext\n",
    "                               }, ignore_index=True)\n",
    "\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info('Getting client_folders_sulphur...')\n",
    "client_folders_sulphur = get_client_folders_from_root_folders(root_folders_sulphur)\n",
    "logging.info('Getting client_folders_texas...')\n",
    "client_folders_texas = get_client_folders_from_root_folders(root_folders_texas)\n",
    "\n",
    "logging.info('Getting project_folders_sulphur...')\n",
    "project_folders_sulphur = get_project_folders_from_client_folders(client_folders_sulphur)\n",
    "logging.info('Getting project_folders_texas...')\n",
    "project_folders_texas = get_project_folders_from_client_folders(client_folders_texas)\n",
    "\n",
    "logging.info('Getting instrument_files_sulphur...')\n",
    "instrument_files_sulphur = get_instrument_files_from_project_folders(project_folders_sulphur)\n",
    "logging.info('Getting instrument_files_texas...')\n",
    "instrument_files_texas = get_instrument_files_from_project_folders(project_folders_texas)\n",
    "\n",
    "project_part_sulphur = 3\n",
    "project_part_texas = 4\n",
    "\n",
    "df = process_instrument_files(instrument_files_sulphur, project_part_sulphur, df)\n",
    "df = process_instrument_files(instrument_files_texas, project_part_texas, df)\n",
    "\n",
    "#df.to_excel(instrument_destination_parent + '\\index_' + datetime.today().strftime('%Y-%m-%d') + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting df_new_datasheets...\n",
      "df_new_datasheets.shape(): (9, 13)\n",
      "Creating a file for new datasheets and saving at E:\\OneDrive\\My Programming Projects\\Get Instrument Datasheets\\Go-Bys - Instrument Datasheets\\index-new-records_2019-11-19-0901.xlsx ...\n"
     ]
    }
   ],
   "source": [
    "logging.info('Getting df_new_datasheets...')\n",
    "print('Getting df_new_datasheets...')\n",
    "df_new_datasheets = df[df.STATUS == 'New']\n",
    "\n",
    "print(\"df_new_datasheets.shape():\", df_new_datasheets.shape)\n",
    "\n",
    "new_files_filepath = instrument_destination_parent + '\\\\index-new-records_' + datetime.today().strftime('%Y-%m-%d-%H%M') + '.xlsx'\n",
    "logging.info('Creating a file for new datasheets and saving at ' + new_files_filepath)\n",
    "print('Creating a file for new datasheets and saving at', new_files_filepath, '...')\n",
    "df_new_datasheets.to_excel(new_files_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse through the Datasheets and map using the master mapping program.\n",
    "Resource: https://realpython.com/openpyxl-excel-spreadsheets-python/\n",
    "## Have the Spec Sheet Manager and LPO Program automatically load this data when a new file is added to the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import numpy as np\n",
    "from openpyxl.utils.cell import coordinate_from_string, column_index_from_string\n",
    "\n",
    "def get_df_map():\n",
    "    #print('Getting dataframe for map file ...')\n",
    "    #path_to_datasheet_map = 'datasheet_map.xlsx'\n",
    "    path_to_datasheet_map = \"E:\\\\OneDrive\\\\My Programming Projects\\\\Get Instrument Datasheets\\\\datasheet_map.xlsx\"\n",
    "    try:\n",
    "        df_map = pd.read_excel(path_to_datasheet_map)\n",
    "        return df_map\n",
    "    except:\n",
    "        logging.error('Unable to create df_map for ' + path_to_datasheet_map)\n",
    "        exit(0)\n",
    "    \n",
    "\n",
    "def find_datasheet_map_for_xls_xlsx_xlsm(path, df_map):\n",
    "    #print('Searching the map for a match to', path, '...')\n",
    "    try:\n",
    "        workbook = xlrd.open_workbook(filename=path)\n",
    "        worksheet = workbook.sheet_by_index(0) # test the first worksheet in the workbook.  TODO: Test each worksheet in the workbook.\n",
    "    except:\n",
    "        #print(\"Error Opening Workbook in find_datasheet_map_for_xls_xlsx_xlsm\")\n",
    "        return \"Error Opening Workbook in find_datasheet_map_for_xls_xlsx_xlsm\"\n",
    "    #path_to_datasheet_map = 'datasheet_map.xlsx'\n",
    "    #df_map = get_df_map() #pd.read_excel(path_to_datasheet_map)\n",
    "    \n",
    "    for i, row in df_map.iterrows():\n",
    "        item = row['Key Cells']\n",
    "        key_cells_list = item.strip('{}').split(\"', \")\n",
    "        result = datasheet_match(i, key_cells_list, worksheet)\n",
    "        if result == True:\n",
    "            #print('Match found at index', i)\n",
    "            return i\n",
    "    #print('No match found')\n",
    "    return \"No Match Found\"\n",
    "       \n",
    "def datasheet_match(map_index, key_cells, worksheet):\n",
    "    #print('Comparing worksheet', worksheet.name, 'against map index item', map_index, ' for match to key cells...')#, *key_cells) #, sep = \", \")\n",
    "    for key_cell in key_cells:\n",
    "        rng, key_value = [x.strip(\"'\").strip() for x in key_cell.split(': ', 1)]\n",
    "\n",
    "        xy = coordinate_from_string(rng)\n",
    "        col = column_index_from_string(xy[0])\n",
    "        row = xy[1]\n",
    "\n",
    "        if col>worksheet.ncols or row>worksheet.nrows: return False \n",
    "        datasheet_cell_value = worksheet.cell_value(row-1, col-1)\n",
    "        \n",
    "        if type(datasheet_cell_value) is str:\n",
    "            key_value = key_value.strip()\n",
    "            datasheet_cell_value = datasheet_cell_value.strip()\n",
    "            if key_value != datasheet_cell_value:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def number_of_sheets_in_workbook(filename):\n",
    "    #print('Getting the number of sheets in workbook', filename, '...')\n",
    "    try:\n",
    "        book = xlrd.open_workbook(filename)\n",
    "        return len(book.sheets())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_serv_manuf_model(index, df_map, datasheet_path, map_col_header):\n",
    "    #print('Getting Service, Manufacturer and Model Number from', datasheet_path, '...')\n",
    "    cell = df_map.loc[index][map_col_header]\n",
    "    if isinstance(cell, str):\n",
    "        try:\n",
    "            workbook = xlrd.open_workbook(datasheet_path)\n",
    "            worksheet = workbook.sheet_by_index(0)\n",
    "            xy = coordinate_from_string(cell)\n",
    "            col = column_index_from_string(xy[0])\n",
    "            row = xy[1]\n",
    "            return worksheet.cell_value(row-1, col-1)\n",
    "        except:\n",
    "            return 'ERROR IN get_serv_manuf_model'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info('Getting df_map...')\n",
    "df_map = get_df_map()\n",
    "\n",
    "logging.info('Getting df_datasheets...')\n",
    "#df_datasheets = pd.read_excel(new_files_filepath)\n",
    "df_datasheets = pd.read_excel('E:\\\\OneDrive\\\\My Programming Projects\\\\Get Instrument Datasheets\\\\Go-Bys - Instrument Datasheets\\\\index-new-records_2019-11-21-0107.xlsx')\n",
    "\n",
    "logging.info('Adding FILE EXTENSION column to df_datasheets.')\n",
    "df_datasheets['FILE EXTENSION'] = df_datasheets['FILE EXTENSION'].apply(lambda x: x.lower())\n",
    "logging.info('Adding MATCH column to df_datasheets.')\n",
    "df_datasheets['MATCH'] = np.nan\n",
    "\n",
    "logging.info('Creating df_excel as a subset of df_datasheets by filtering FILE EXTENSION for .xls, .xlsx, and .xlsm')\n",
    "df_excel = df_datasheets[df_datasheets['FILE EXTENSION'].isin(['.xls', '.xlsx', '.xlsm'])]\n",
    "logging.info('Creating df_doc_docx_docm as a subset of df_datasheets by filtering FILE EXTENSION for .doc, .docx, and .docm')\n",
    "df_doc_docx_docm = df_datasheets[df_datasheets['FILE EXTENSION'].isin(['.doc', '.docx', '.docm'])]\n",
    "\n",
    "logging.info('Adding SHEET COUNT column to df_datasheets.')\n",
    "df_datasheets['SHEET COUNT'] = df_excel['DESTINATION PATH'].apply(number_of_sheets_in_workbook)\n",
    "#df_datasheets['MATCH'] = df_excel['DESTINATION PATH'].apply(find_datasheet_map_for_xls_xlsx_xlsm)\n",
    "logging.info('Adding MATCH column to df_datasheets.')\n",
    "df_datasheets['MATCH'] = df_excel.apply(lambda x: find_datasheet_map_for_xls_xlsx_xlsm(x['DESTINATION PATH'], df_map), axis=1 )\n",
    "\n",
    "logging.info('Creating df_match_is_str by checking to see if df_datasheets[\\'MATCH\\'] is an instance of str.')\n",
    "df_match_is_str = df_datasheets[df_datasheets['MATCH'].apply(lambda x: isinstance(x, (str)))]\n",
    "if df_match_is_str.shape[0] > 0:\n",
    "    logging.info('Creating df_no_matches by filtering df_datasheets[\\'MATCH\\'] to \\'No Match Found\\'.')\n",
    "    df_no_matches = df_datasheets[df_datasheets['MATCH'] == 'No Match Found']\n",
    "    df_no_matches.to_excel(instrument_destination_parent + '\\\\_no matches found\\\\no-matches_' + datetime.today().strftime('%Y-%m-%d-%H%M') + '.xlsx')\n",
    "\n",
    "logging.info('Creating df_matches by filtering df_datasheets[\\'MATCH\\'] for numeric types.')\n",
    "df_matches = df_datasheets[df_datasheets['MATCH'].astype(str).str.isnumeric()]\n",
    "df_matches_nonulls = df_matches[df_matches['MATCH'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if df_matches_nonulls.shape[0]>0:\n",
    "    logging.info('Adding SERVICE DESCRIPTION to df_datasheets.')\n",
    "    df_datasheets['SERVICE DESCRIPTION'] = df_matches_nonulls.apply(lambda x: get_serv_manuf_model(x['MATCH'], df_map, x['DESTINATION PATH'], 'Service Cell'), axis=1)\n",
    "    logging.info('Adding MANUFACTURER to df_datasheets.')\n",
    "    df_datasheets['MANUFACTUER'] = df_matches_nonulls.apply(lambda x: get_serv_manuf_model(x['MATCH'], df_map, x['DESTINATION PATH'], 'Manufacturer Cell'), axis=1)\n",
    "    logging.info('Adding MODEL NUMBER to df_datasheets.')\n",
    "    df_datasheets['MODEL NUMBER'] = df_matches_nonulls.apply(lambda x: get_serv_manuf_model(x['MATCH'], df_map, x['DESTINATION PATH'], 'Model Number Cell'), axis=1)\n",
    "\n",
    "#df_datasheets['MATCH'].apply(lambda x: isinstance(x, (int, float)))\n",
    "#df_datasheets.to_excel(\"index.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index.xlsx...\n",
      "Appending new datasheets to index...\n",
      "Saving index...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "logging.info('Loading existing index.xlsx.')\n",
    "print('Loading existing index.xlsx...')\n",
    "df_index = pd.read_excel(instrument_destination_parent + '\\index.xlsx')\n",
    "logging.info('Appending new datasheets to index.')\n",
    "print('Appending new datasheets to index...')\n",
    "df_index = df_index.append(df_datasheets, ignore_index = True)\n",
    "logging.info('Saving index.')\n",
    "print('Saving index...')\n",
    "df_index.to_excel(instrument_destination_parent + '\\index.xlsx')\n",
    "logging.info('Complete')\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
